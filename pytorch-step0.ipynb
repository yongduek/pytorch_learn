{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see 'https://pytorch.org/docs/stable/torch.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2x3 = th.tensor([ [0.1, 1.2], [2.2, 3.3], [4.4, 5.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1000,  1.2000],\n",
      "        [ 2.2000,  3.3000],\n",
      "        [ 4.4000,  5.5000]])\n"
     ]
    }
   ],
   "source": [
    "print (t2x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array ([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t =  tensor([-1,  2,  3], dtype=torch.int32)\n",
      "a =  [-1  2  3]\n"
     ]
    }
   ],
   "source": [
    "t = th.from_numpy (a)   # soft copy of numpy array\n",
    "print ('t = ', t)\n",
    "t[0] = -1\n",
    "print ('a = ', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.zeros_like (t, dtype=th.float32) # the same shape as the tensor t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f94e8a0950>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.manual_seed (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = th.empty(3,3).uniform_(0,1) # uniform_() is an in-place random sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9699,  0.1078,  0.8829],\n",
       "        [ 0.4132,  0.7572,  0.6948],\n",
       "        [ 0.5209,  0.5932,  0.8797]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.bernoulli (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -0.1138,   2.2570,   2.9508,   4.4593,   5.0223,   5.7602,\n",
       "          7.6857,   7.9751,   8.6277,  10.0732])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.normal (mean=th.arange(1.,11.), std=th.arange(1,0,-0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.arange(1.,11.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0260,  0.6073, -1.6128]])\n"
     ]
    }
   ],
   "source": [
    "t = th.randn(1,3) # Normal Random of size 1x3\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 cpu torch.strided\n"
     ]
    }
   ],
   "source": [
    "print (t.dtype, t.device, t.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcuda = th.randn(1,3).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0443,  0.2187, -0.0672]], device='cuda:0') torch.float32 cuda:0 torch.strided\n"
     ]
    }
   ],
   "source": [
    "print(tcuda, tcuda.dtype, tcuda.device, tcuda.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dev = th.device('cuda:0')\n",
    "print (dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7519,  0.1969,  0.6995],\n",
      "        [-0.0536,  1.0777, -0.8029]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tt = th.randn((2,3), device=dev)\n",
    "print (tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x1f952a1e278>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.7588,  0.7981,  0.0782,  0.7314],\n",
      "          [ 0.2632,  0.7995,  0.7100,  0.9718],\n",
      "          [ 0.6003,  0.4355,  0.3343,  0.2836],\n",
      "          [ 0.7499,  0.6684,  0.4513,  0.8876]]]])\n",
      "Any data for input to NN must be of shape [batch, channel, rows, cols]\n"
     ]
    }
   ],
   "source": [
    "img = th.rand(1,1,4,4); \n",
    "print (img)\n",
    "print ('Any data for input to NN must be of shape [batch, channel, rows, cols]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f913774390>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow (img[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5397,  0.7127,  0.4642,  0.0925,  0.6242,  0.0526,  0.4800])\n"
     ]
    }
   ],
   "source": [
    "v = th.rand(7); print (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel (nn.Module):\n",
    "    def __init__(self):\n",
    "        super (myModel, self).__init__()\n",
    "        self.c1 = nn.Conv2d (1,3, 2)\n",
    "        self.relu1 = F.relu\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.relu1 (x)\n",
    "        return x\n",
    "    #\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myModel(\n",
      "  (c1): Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = myModel()\n",
    "print (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.1932,  0.0359],\n",
       "          [ 0.0053,  0.0000,  0.0000],\n",
       "          [ 0.1262,  0.0889,  0.0000]],\n",
       "\n",
       "         [[ 0.1795,  0.0686,  0.7161],\n",
       "          [ 0.3623,  0.0000,  0.0556],\n",
       "          [ 0.2531,  0.1406,  0.2733]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0592,  0.0891],\n",
       "          [ 0.0000,  0.0000,  0.0000]]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m =  Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "img =  torch.Size([1, 1, 4, 4]) tensor([[[[ 0.7588,  0.7981,  0.0782,  0.7314],\n",
      "          [ 0.2632,  0.7995,  0.7100,  0.9718],\n",
      "          [ 0.6003,  0.4355,  0.3343,  0.2836],\n",
      "          [ 0.7499,  0.6684,  0.4513,  0.8876]]]])\n",
      "out =  torch.Size([1, 3, 4, 4]) tensor([[[[-0.1318, -0.2435, -0.5610, -0.3941],\n",
      "          [-0.2017, -0.3219, -0.5337,  0.0233],\n",
      "          [-0.2358, -0.3710, -0.5186, -0.4093],\n",
      "          [ 0.0204, -0.1944, -0.2477, -0.0489]],\n",
      "\n",
      "         [[-0.0616, -0.0876, -0.3534,  0.0598],\n",
      "          [ 0.2947,  0.2640, -0.0391,  0.0255],\n",
      "          [ 0.2820,  0.1760,  0.4117,  0.5000],\n",
      "          [ 0.1015,  0.0571, -0.1007,  0.0693]],\n",
      "\n",
      "         [[ 0.7287,  0.4894,  0.6167,  0.6077],\n",
      "          [ 0.5893,  1.0155,  0.6200,  0.4943],\n",
      "          [ 0.5016,  0.5437,  0.6166,  0.8284],\n",
      "          [ 0.5467,  0.4908,  0.5442,  0.4627]]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Conv2d(1, # in_channels\n",
    "              3, # out_channels\n",
    "              3, # kernel_size,\n",
    "              stride=1, padding=1)\n",
    "print ('m = ', m)\n",
    "output = m(img)\n",
    "print ('img = ', img.shape, img)\n",
    "print ('out = ', output.shape, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in: torch.Size([4, 4]) out: torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "upsample = nn.ConvTranspose2d (1, 1, kernel_size=3, stride=1, padding=0)\n",
    "o2 = upsample (img)\n",
    "print ('in:', output.shape[2:], 'out:', o2.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in: torch.Size([6, 6]) out: torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "o3 = upsample (o2)\n",
    "print ('in:', o2.shape[2:], 'out:', o3.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in: torch.Size([4, 4]) out: torch.Size([9, 9])\n"
     ]
    }
   ],
   "source": [
    "upsample = nn.ConvTranspose2d (1, 1, kernel_size=3, stride=2, padding=0)\n",
    "o2 = upsample (img)\n",
    "print ('in:', output.shape[2:], 'out:', o2.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1318, -0.2435, -0.5610, -0.3941],\n",
       "          [-0.2017, -0.3219, -0.5337,  0.0233],\n",
       "          [-0.2358, -0.3710, -0.5186, -0.4093],\n",
       "          [ 0.0204, -0.1944, -0.2477, -0.0489]],\n",
       "\n",
       "         [[-0.0616, -0.0876, -0.3534,  0.0598],\n",
       "          [ 0.2947,  0.2640, -0.0391,  0.0255],\n",
       "          [ 0.2820,  0.1760,  0.4117,  0.5000],\n",
       "          [ 0.1015,  0.0571, -0.1007,  0.0693]],\n",
       "\n",
       "         [[ 0.7287,  0.4894,  0.6167,  0.6077],\n",
       "          [ 0.5893,  1.0155,  0.6200,  0.4943],\n",
       "          [ 0.5016,  0.5437,  0.6166,  0.8284],\n",
       "          [ 0.5467,  0.4908,  0.5442,  0.4627]]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "down = nn.Conv2d (1,1, kernel_size=3, stride=1)\n",
    "up = nn.ConvTranspose2d (1,1, kernel_size=3, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = th.randn(1,1,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 14, 14])\n",
      "torch.Size([1, 1, 12, 12])\n",
      "torch.Size([1, 1, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "o1 = down(input); print (o1.shape)\n",
    "o2 = down(o1); print (o2.shape)\n",
    "o3 = down(o2); print (o3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "u1 = up (o3); print (u1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "u2 = up (u1); print (u2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "u3 = up (u2); print (u3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "down2 = nn.Conv2d (1,1, kernel_size=3, stride=1,padding=1)\n",
    "up2 = nn.ConvTranspose2d (1,1, kernel_size=3, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 16, 16]) torch.Size([1, 1, 16, 16]) Equal shape:  True\n"
     ]
    }
   ],
   "source": [
    "o1 = down2 (input); \n",
    "print (o1.shape, input.shape, 'Equal shape: ', o1.shape == input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
